
# CHAT WITH ML

## Description

"Chat with ML" is a chatbot application designed to assist users in learning about machine learning. Powered by the Llama 3 language model, this chatbot has been fine-tuned on a collection of machine learning books. It aims to provide accurate and insightful responses to queries, covering topics from beginner to advanced levels. Whether you're new to machine learning or looking to solidify your foundational knowledge, "Chat with ML" serves as an accessible and educational tool to enhance your understanding.


## ðŸš€ About Us
We are a team of 6 enthusiasts dedicated to creating an accessible and educational chatbot that helps users learn about machine learning concepts. We take our work seriously but also believe in having fun and fostering a collaborative environment.


## Features
-->Provides accurate answers to machine learning queries

-->Covers topics from beginner to basic levels

-->User-friendly interface
## Installation



### Frontend

1. **Clone the repository:**
   ```bash
   git clone https://github.com/v-Shivaprasad/Chat-with-ML
   ```

2. **Navigate to the project directory:**
   ```bash
   cd 'Chat with ML'
   ```

3. **Install frontend dependencies:**
   ```bash
   npm install 
   ```

4. **Run the frontend application:**
   ```bash
   npm run dev
   ```

### Backend

1. **Navigate to the server directory:**
   ```bash
   cd 'server'
   ```

2. **Install backend dependencies:**
   ```bash
   npm install 
   ```

3. **Run the backend application using nodemon:**
   ```bash
   nodemon start
   ```
4. **Important Note:**
Before running the backend, make sure to host the tuned model as an API. You can do this by running the llamahosting.ipynb notebook. Use the output API endpoint (website API) provided by the notebook to connect to llm in your backend.

    
